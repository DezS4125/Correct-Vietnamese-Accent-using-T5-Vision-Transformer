{"cells":[{"cell_type":"markdown","metadata":{"id":"uVWe-Np2SrIA"},"source":["## Train"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":52777,"status":"ok","timestamp":1701250632582,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"G7BBg2SNEaDa"},"outputs":[],"source":["%%capture\n","!pip install datasets evaluate transformers[sentencepiece]\n","!pip install rouge_score\n","!pip install transformers[torch]\n","!pip install csv\n","!pip install pandas\n","!pip install scikit-learn"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1701250632584,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"wTz6PZF8EgxX"},"outputs":[],"source":["# !gsutil cp -r gs://vietai_public/viT5/data/vietnews .\n","# !gsutil cp -r gs://vietai_public/viT5/data/wikilingua .\n"]},{"cell_type":"markdown","metadata":{"id":"9UgBnjMQ_IU7"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1085258,"status":"ok","timestamp":1701251717828,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"kAPOKO_g0wiq","outputId":"79f9c21c-cd72-4672-9049-91a03925925c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /colabDrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/colabDrive')\n","# filePath=\"/colabDrive/MyDrive/colabDrive/hyperSmallDataset.csv\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15627,"status":"ok","timestamp":1701251733446,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"eDuUZV7nF4IL"},"outputs":[],"source":["from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader\n","import csv"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":22955,"status":"ok","timestamp":1701251756391,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"ah6qWnJtF-Wn"},"outputs":[],"source":["%%capture\n","tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"/colabDrive/MyDrive/colabDrive/ModelStep7\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1701251756392,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"YgIAqjmjF9UC"},"outputs":[],"source":["def preprocess_function(examples):\n","    model_inputs = tokenizer(\n","        examples[\"inputs\"], max_length=512, truncation=True, padding=True\n","    )\n","\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples[\"labels\"], max_length=512, truncation=True, padding=True\n","        )\n","    model_inputs['labels'] = labels['input_ids']\n","    model_inputs['input_ids'] = model_inputs['input_ids']\n","    return model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Obl3e6AFGzI"},"outputs":[],"source":["# Deprecated\n","# input_lines = []\n","# label_lines = []\n","\n","# train_file = '/colabDrive/MyDrive/colabDrive/miniDataset.csv'\n","\n","# with open(f'{train_file}', newline='') as file:\n","#     reader = csv.reader(file)\n","#     for line in reader:\n","#         input_lines.append(line[0] +'\u003c/s\u003e')\n","#         label_lines.append(line[1])\n","\n","# dict_obj = {'inputs': input_lines, 'labels': label_lines}\n","# dataset = Dataset.from_dict(dict_obj)\n","# tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"za6PxflV5AzJ"},"outputs":[],"source":["\n","# input_lines"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"executionInfo":{"elapsed":18379,"status":"ok","timestamp":1701251774761,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"1F0kc2dM4RPD","outputId":"520a54c3-375e-4ae2-e1c9-cf1962722f96"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3092c774a40446d58781caf63b3a8e7c","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=8):   0%|          | 0/20000 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87360970991c4b87b45e71c3b9ed2c8f","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=8):   0%|          | 0/5000 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","train_file = '/colabDrive/MyDrive/colabDrive/output_file_8.csv'\n","# Read the CSV file using pandas\n","df = pd.read_csv(train_file)\n","\n","# Assuming `dataset` is your original dataset\n","train_dataset, eval_dataset = train_test_split(df, test_size=0.2)\n","\n","def prepareDataset(df):\n","    # Convert the columns to lists\n","    input_lines = df['AccentlessSentences'].tolist()\n","    label_lines = df['Sentences'].tolist()\n","\n","    # Append '\u003c/s\u003e' to each input line\n","    input_lines = [line + '\u003c/s\u003e' for line in input_lines]\n","\n","    dict_obj = {'inputs': input_lines, 'labels': label_lines}\n","    dataset = Dataset.from_dict(dict_obj)\n","    tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)\n","    return tokenized_datasets\n","\n","tokenized_training_datasets=prepareDataset(train_dataset)\n","tokenized_eval_datasets=prepareDataset(eval_dataset)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1701251774762,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"L_nU1kIsyR7x","outputId":"2b193d9b-126c-4135-b3c3-e08271622d95"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 5000\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_eval_datasets"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1701251774763,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"JHiwgkvsGfVD"},"outputs":[],"source":["\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(\"tmp/\",\n","                                      do_train=True,\n","                                      do_eval=True,\n","                                      num_train_epochs=2,\n","                                      learning_rate=1e-5,\n","                                      warmup_ratio=0.05,\n","                                      weight_decay=0.01,\n","                                      per_device_train_batch_size=5,\n","                                      per_device_eval_batch_size=5,\n","                                      logging_dir='./log',\n","                                      group_by_length=True,\n","                                      save_strategy=\"steps\",\n","                                      save_steps=500,\n","                                      save_total_limit=3,\n","                                      evaluation_strategy=\"steps\",\n","                                      eval_steps=500,\n","                                      logging_strategy=\"steps\",\n","                                      logging_steps=500,\n","                                      fp16=True,\n","                                      )\n","\n","\n","# training_args = Seq2SeqTrainingArguments(\"tmp/\",\n","#                                       do_train=True,\n","#                                       do_eval=True,\n","#                                       num_train_epochs=2,\n","#                                       learning_rate=1e-5,\n","#                                       warmup_ratio=0.05,\n","#                                       weight_decay=0.01,\n","#                                       per_device_train_batch_size=5,\n","#                                       per_device_eval_batch_size=5,\n","#                                       logging_dir='./log',\n","#                                       group_by_length=True,\n","#                                       save_strategy=\"epoch\",\n","#                                       save_total_limit=3,\n","#                                       evaluation_strategy=\"epoch\",\n","#                                       logging_strategy=\"epoch\",\n","#                                       fp16=True,\n","#                                       )\n","\n","\n","\n","# AdaFactor for ViT5-large models as it based on T5v1.1.\n","# See https://medium.com/the-artificial-impostor/paper-adafactor-adaptive-learning-rates-with-sublinear-memory-cost-a543abffa37\n","#\n","# from transformers.optimization import Adafactor, AdafactorSchedule\n","# optimizer = Adafactor(\n","#     model.parameters(),\n","#     lr=1e-3,\n","#     eps=(1e-30, 1e-3),\n","#     clip_threshold=1.0,\n","#     decay_rate=-0.8,\n","#     beta1=None,\n","#     weight_decay=0.0,\n","#     relative_step=False,\n","#     scale_parameter=False,\n","#     warmup_init=False\n","# )\n","# lr_scheduler = AdafactorSchedule(optimizer)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":739},"executionInfo":{"elapsed":6939239,"status":"ok","timestamp":1701259442624,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"2lnrMZZJHro8"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [8000/8000 2:07:35, Epoch 2/2]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e500\u003c/td\u003e\n","      \u003ctd\u003e0.006100\u003c/td\u003e\n","      \u003ctd\u003e0.003563\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1000\u003c/td\u003e\n","      \u003ctd\u003e0.005900\u003c/td\u003e\n","      \u003ctd\u003e0.003526\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1500\u003c/td\u003e\n","      \u003ctd\u003e0.005800\u003c/td\u003e\n","      \u003ctd\u003e0.003435\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2000\u003c/td\u003e\n","      \u003ctd\u003e0.005500\u003c/td\u003e\n","      \u003ctd\u003e0.003265\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2500\u003c/td\u003e\n","      \u003ctd\u003e0.005100\u003c/td\u003e\n","      \u003ctd\u003e0.003186\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3000\u003c/td\u003e\n","      \u003ctd\u003e0.005200\u003c/td\u003e\n","      \u003ctd\u003e0.003154\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3500\u003c/td\u003e\n","      \u003ctd\u003e0.004700\u003c/td\u003e\n","      \u003ctd\u003e0.003122\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4000\u003c/td\u003e\n","      \u003ctd\u003e0.004400\u003c/td\u003e\n","      \u003ctd\u003e0.003088\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4500\u003c/td\u003e\n","      \u003ctd\u003e0.003800\u003c/td\u003e\n","      \u003ctd\u003e0.003123\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5000\u003c/td\u003e\n","      \u003ctd\u003e0.003500\u003c/td\u003e\n","      \u003ctd\u003e0.003100\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5500\u003c/td\u003e\n","      \u003ctd\u003e0.003200\u003c/td\u003e\n","      \u003ctd\u003e0.003071\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6000\u003c/td\u003e\n","      \u003ctd\u003e0.003500\u003c/td\u003e\n","      \u003ctd\u003e0.003015\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6500\u003c/td\u003e\n","      \u003ctd\u003e0.003200\u003c/td\u003e\n","      \u003ctd\u003e0.002969\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7000\u003c/td\u003e\n","      \u003ctd\u003e0.003700\u003c/td\u003e\n","      \u003ctd\u003e0.002967\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7500\u003c/td\u003e\n","      \u003ctd\u003e0.003300\u003c/td\u003e\n","      \u003ctd\u003e0.002962\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8000\u003c/td\u003e\n","      \u003ctd\u003e0.003200\u003c/td\u003e\n","      \u003ctd\u003e0.002950\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=8000, training_loss=0.004368598654866219, metrics={'train_runtime': 7657.5245, 'train_samples_per_second': 5.224, 'train_steps_per_second': 1.045, 'total_flos': 1.88314102395648e+16, 'train_loss': 0.004368598654866219, 'epoch': 2.0})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_training_datasets,\n","    eval_dataset=tokenized_eval_datasets,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"8ZjoI9wAYdao","outputId":"b26286ee-99cd-4cb8-b231-0c521fe12260"},"outputs":[{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='9' max='1000' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [   9/1000 00:01 \u003c 02:44, 6.01 it/s]\n","    \u003c/div\u003e\n","    "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["\n","# After training, you can evaluate the model like this:\n","metrics = trainer.evaluate()\n","\n","print(metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dPV5TvzJ7CJf"},"outputs":[],"source":["\n","# Save the model\n","trainer.save_model('/colabDrive/MyDrive/colabDrive/ModelStep8')\n","#tokenizer.save_pretrained(\"/colabDrive/MyDrive/colabDrive/myTokenizer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMYqf2JTrG-F"},"outputs":[],"source":["trainer.state.log_history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VYddx-Yui_w"},"outputs":[],"source":["import json\n","\n","with open(\"/colabDrive/MyDrive/colabDrive/log_history8.json\", \"w\") as f:\n","    json.dump(trainer.state.log_history, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sr-qXopCYoKe"},"outputs":[],"source":["# Draw a graph\n","\n","import matplotlib.pyplot as plt\n","\n","# Assuming that 'history' is your training history\n","def plot_graphs(history):\n","    # Extract values from the history\n","    # accuracy = [x['eval_accuracy'] for x in history if 'eval_accuracy' in x]\n","    train_loss = [x['loss'] for x in history if 'loss' in x]\n","    eval_loss = [x['eval_loss'] for x in history if 'eval_loss' in x]\n","\n","    # Extract step values\n","    steps = [x['step'] for x in history if ('loss' in x or 'eval_loss' in x)]\n","    # Remove duplicates and preserve order\n","    steps = list(dict.fromkeys(steps))\n","    # print(steps[:-1])\n","    # Plot the losses\n","    plt.figure(figsize=(10,5))\n","    plt.plot(steps, train_loss, label='Train Loss')\n","    plt.plot(steps, eval_loss[:-1] , label='Eval Loss')\n","    plt.xlabel('Steps')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.title('Training and Validation Loss')\n","    plt.show()\n","\n","\n","\n","# Call the function\n","plot_graphs(trainer.state.log_history)"]},{"cell_type":"markdown","metadata":{"id":"XzEWbrNMSo8c"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":2631,"status":"ok","timestamp":1698982204638,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"BHCiygFJ7RhP","outputId":"81aa5378-8fe4-4843-baf6-2ed93c73a28e"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-18-ffe5587f2e49\u003e:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"rouge\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea0631dece304fc6a8553857aeea67c0","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_metric\n","metric = load_metric(\"rouge\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"executionInfo":{"elapsed":3850,"status":"ok","timestamp":1698982208483,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"55vewVrY7UG3","outputId":"b4dbb61b-74c8-40d4-8253-4812dac0e060"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c67b00392954088952f6de0c8ae4576","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=10):   0%|          | 0/5000 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["import pandas as pd\n","train_file = '/colabDrive/MyDrive/colabDrive/output_file_10.csv'\n","# Read the CSV file using pandas\n","df = pd.read_csv(train_file)\n","\n","# Convert the columns to lists\n","input_lines = df['AccentlessSentences'].tolist()\n","label_lines = df['Sentences'].tolist()\n","\n","# Append '\u003c/s\u003e' to each input line\n","input_lines = [line + '\u003c/s\u003e' for line in input_lines]\n","\n","dict_obj = {'inputs': input_lines, 'labels': label_lines}\n","dataset = Dataset.from_dict(dict_obj)\n","test_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n","\n","# input_lines = []\n","# label_lines = []\n","# with open(f'{task}/test.tsv') as file:\n","#   for line in file:\n","#     line = line.strip().split('\\t')\n","#     input = line[0]\n","#     input_lines.append(input +'\u003c/s\u003e')\n","#     label_lines.append(line[1])\n","\n","\n","\n","# input_lines  = input_lines\n","# label_lines = label_lines\n","# dict_obj = {'inputs': input_lines, 'labels': label_lines}\n","\n","# dataset = Dataset.from_dict(dict_obj)\n","# test_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8107,"status":"ok","timestamp":1698982216586,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"Tk_hB4b-8GkP","outputId":"3a9542d5-7a4e-44b7-8308-1043c9a662b0"},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained('/colabDrive/MyDrive/colabDrive/ModelStep7')\n","tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"elapsed":533748,"status":"ok","timestamp":1698982750321,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"54ckcdzG7Xlc","outputId":"8be3a00f-36c3-48b8-fc42-52262d11c53c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9327de8005964ef2a765fdcd685f5262","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/157 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.9892285612130981, recall=0.988232139301163, fmeasure=0.9886761705932003), mid=Score(precision=0.9900883980878767, recall=0.9890375934018654, fmeasure=0.9894809922586197), high=Score(precision=0.9908715577873408, recall=0.9898502523962159, fmeasure=0.9902774918070639)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.9815587448386798, recall=0.9805784149978447, fmeasure=0.9810106256359842), mid=Score(precision=0.9829013811718406, recall=0.9819138956403426, fmeasure=0.9823234587882588), high=Score(precision=0.9841312640986336, recall=0.9831852457734818, fmeasure=0.9835493282332121)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.9890187282047842, recall=0.9880037330369044, fmeasure=0.9884069150293565), mid=Score(precision=0.9898974089619357, recall=0.9888559682419087, fmeasure=0.9893093644425155), high=Score(precision=0.9907089241996825, recall=0.9897213497194335, fmeasure=0.9901312508322981)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.9890811491660113, recall=0.9880939875655383, fmeasure=0.9885078034925403), mid=Score(precision=0.9898826871841251, recall=0.9888522266875093, fmeasure=0.9892687841971959), high=Score(precision=0.9906532614140849, recall=0.9896849172711197, fmeasure=0.9900501048737546))}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import numpy as np\n","metrics = load_metric('rouge')\n","\n","max_target_length = 512\n","dataloader = torch.utils.data.DataLoader(test_tokenized_datasets, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","  outputs = model.generate(\n","      input_ids=batch['input_ids'].to('cuda'),\n","      max_length=max_target_length,\n","      attention_mask=batch['attention_mask'].to('cuda'),\n","  )\n","  with tokenizer.as_target_tokenizer():\n","    outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","    labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","    actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","  predictions.extend(outputs)\n","  references.extend(actuals)\n","  metrics.add_batch(predictions=outputs, references=actuals)\n","\n","\n","metrics.compute()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18166,"status":"ok","timestamp":1698982768478,"user":{"displayName":"Khang Lam Hoang","userId":"02732529430571730404"},"user_tz":-420},"id":"pXJrSJVz7cOM","outputId":"12c737a8-3ed5-45ef-d4de-e75b78060835"},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.9894809922586197},\n"," {'rouge2': 0.9823234587882588},\n"," {'rougeL': 0.9893093644425155},\n"," {'rougeLsum': 0.9892687841971959}]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOYk_y8nJF3w"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"150rG4my1YZaNaFY_T2VkKDHODRGMcYvt","timestamp":1699018728542},{"file_id":"1bakGR_Zk1Wmg9rJtcHkJJjBsuBMvYONS","timestamp":1698977580560},{"file_id":"1spT0jX3yX_qylZpZKuYheaIuwRpIjcNg","timestamp":1698970702299},{"file_id":"1s50VDFKN5FcTBSpAXG7oW0JXkyBcYnC4","timestamp":1698734148458},{"file_id":"1RvAHknFdC6KwV6O-ZPz_uSrTxgDS0FwH","timestamp":1698673695995},{"file_id":"18GXrjFqgUuatdcaIaadMJWjLrZbw4vzJ","timestamp":1698648151157},{"file_id":"1PfF-A0PCLj69B3YhdnWdFfVgAJUgcOKY","timestamp":1698640967078}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.7"},"vscode":{"interpreter":{"hash":"eedb55a3f3d5a08c90a45b02edd9d5201f64a9996f64fdac14a22b56503f46e8"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"02f99aa35bf741e18d82909c1adbe3a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07ac4ee639c1446e8727f258532ecca6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba55531af1484b9591e9e4d91ed9b402","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85b325ec135847f49143312d0de3248f","value":5000}},"0ed716e8491641e9b6df484fce2fe5c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"176c2c8c8ccf44efac44372098f0656f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fd9c4611beb4ac4922ccd148f4e02d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2320641b137f4e41bbe8da14da916eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3092c774a40446d58781caf63b3a8e7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee9cb5614c5b4de8bee434f5be68154b","IPY_MODEL_326f42508d194781b1f5ffbeae6ba08b","IPY_MODEL_7f4dcbbe2609464dbb03701a6f64456e"],"layout":"IPY_MODEL_93802fb5854a4b9c84564fa22bd099c7"}},"326f42508d194781b1f5ffbeae6ba08b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d90b8b829d74961b01ef6efa843c009","max":20000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ed716e8491641e9b6df484fce2fe5c1","value":20000}},"33a76346164842f696fd5693e2440e8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f62faa4360442d39f71e7a8ee611c55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"407ad48ada6a48e1bc6a0379761828f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"428117e1ec314efd88d5977bc4187427":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4471eb2fe28a437bbca6905407f4053f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44cb5d823e674ca7b4a99f1d28649665":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86de5ed17f074edaa45ca8104790d03b","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f317de627b5e4aa988ee98f5b2019a17","value":5000}},"4856a82feffc4adaa2a1d04f04dd1f59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b8a83de192440318543c0e5487cbcec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bad74ef93d741e6b92c2924f0c20395":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c0cdc07dd40481e9acc18b7a26922dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fbe7b8f8cf3482898fe7a10c52ef079":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5312455c5c3c4b18ab451afda35e2c94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"578038d36980436fa43fde822c477a3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5afd8e653d224357ab71e8018e08726d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c67b00392954088952f6de0c8ae4576":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7480b1c786da45f69a9dc6362436a13e","IPY_MODEL_07ac4ee639c1446e8727f258532ecca6","IPY_MODEL_b94f28ed42114accabfd6c5a98e423a6"],"layout":"IPY_MODEL_02f99aa35bf741e18d82909c1adbe3a6"}},"5e5d97cc12a1431d89a08662dcecd725":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bad74ef93d741e6b92c2924f0c20395","placeholder":"​","style":"IPY_MODEL_4471eb2fe28a437bbca6905407f4053f","value":" 5.65k/? [00:00\u0026lt;00:00, 392kB/s]"}},"61eb4c9bfd85438a9a5b8c27ee9382f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627a27713255438b9f062996c58fd4ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cd3d58d75d041c58599cef70017a455":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61eb4c9bfd85438a9a5b8c27ee9382f5","placeholder":"​","style":"IPY_MODEL_a95ee05692ea4607960cb3d88a85fac4","value":"100%"}},"6d90b8b829d74961b01ef6efa843c009":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7480b1c786da45f69a9dc6362436a13e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_578038d36980436fa43fde822c477a3c","placeholder":"​","style":"IPY_MODEL_33a76346164842f696fd5693e2440e8f","value":"Map (num_proc=10): 100%"}},"7f4dcbbe2609464dbb03701a6f64456e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b8a83de192440318543c0e5487cbcec","placeholder":"​","style":"IPY_MODEL_7fc3c8bc5de0435b90e5e53337da66fc","value":" 20000/20000 [00:12\u0026lt;00:00, 2010.24 examples/s]"}},"7fc3c8bc5de0435b90e5e53337da66fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85b325ec135847f49143312d0de3248f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86de5ed17f074edaa45ca8104790d03b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87360970991c4b87b45e71c3b9ed2c8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce9942f1ba4f4a508f0266b7ffede3a2","IPY_MODEL_44cb5d823e674ca7b4a99f1d28649665","IPY_MODEL_d36a8456929a44c9a8eec55dd6c80c33"],"layout":"IPY_MODEL_4c0cdc07dd40481e9acc18b7a26922dd"}},"8e661682a0dd4bb69bd6e616e76fe491":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fd9c4611beb4ac4922ccd148f4e02d7","max":2169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f62faa4360442d39f71e7a8ee611c55","value":2169}},"9327de8005964ef2a765fdcd685f5262":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cd3d58d75d041c58599cef70017a455","IPY_MODEL_e516070c04a64b2aaa94d9808dbdc060","IPY_MODEL_d5a50475593c40c7918d19b44886fb14"],"layout":"IPY_MODEL_e682170d4bb940a682eefba639c0074f"}},"93802fb5854a4b9c84564fa22bd099c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9575bbfd302b4b1495fa7bd2eada056b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ef358cc2ec4864ad016674347be61f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c0403bec47a436bb2ebd9d4ee9cc4ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a95ee05692ea4607960cb3d88a85fac4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5c696cc2ff04cadbdc83fbdfc48562d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b94f28ed42114accabfd6c5a98e423a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5312455c5c3c4b18ab451afda35e2c94","placeholder":"​","style":"IPY_MODEL_2320641b137f4e41bbe8da14da916eb3","value":" 5000/5000 [00:02\u0026lt;00:00, 3165.43 examples/s]"}},"ba55531af1484b9591e9e4d91ed9b402":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3fb4a8c4c624dd6aee7ee36914dc4a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_627a27713255438b9f062996c58fd4ad","placeholder":"​","style":"IPY_MODEL_e6664635c3c44c41a7592ff4eb1e136d","value":"Downloading builder script: "}},"ce9942f1ba4f4a508f0266b7ffede3a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5c696cc2ff04cadbdc83fbdfc48562d","placeholder":"​","style":"IPY_MODEL_f8768098436a4735a09098953cdc8819","value":"Map (num_proc=8): 100%"}},"d36a8456929a44c9a8eec55dd6c80c33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c0403bec47a436bb2ebd9d4ee9cc4ab","placeholder":"​","style":"IPY_MODEL_95ef358cc2ec4864ad016674347be61f","value":" 5000/5000 [00:03\u0026lt;00:00, 2504.37 examples/s]"}},"d5a50475593c40c7918d19b44886fb14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fbe7b8f8cf3482898fe7a10c52ef079","placeholder":"​","style":"IPY_MODEL_176c2c8c8ccf44efac44372098f0656f","value":" 157/157 [08:28\u0026lt;00:00,  5.02s/it]"}},"e516070c04a64b2aaa94d9808dbdc060":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_428117e1ec314efd88d5977bc4187427","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_407ad48ada6a48e1bc6a0379761828f9","value":157}},"e6664635c3c44c41a7592ff4eb1e136d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e682170d4bb940a682eefba639c0074f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea0631dece304fc6a8553857aeea67c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3fb4a8c4c624dd6aee7ee36914dc4a9","IPY_MODEL_8e661682a0dd4bb69bd6e616e76fe491","IPY_MODEL_5e5d97cc12a1431d89a08662dcecd725"],"layout":"IPY_MODEL_4856a82feffc4adaa2a1d04f04dd1f59"}},"ee9cb5614c5b4de8bee434f5be68154b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9575bbfd302b4b1495fa7bd2eada056b","placeholder":"​","style":"IPY_MODEL_5afd8e653d224357ab71e8018e08726d","value":"Map (num_proc=8): 100%"}},"f317de627b5e4aa988ee98f5b2019a17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8768098436a4735a09098953cdc8819":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}