{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfd6e47-552d-436c-9b19-6f8fe60883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_strings(str1, str2):\n",
    "    # Split the strings into words\n",
    "    words1 = str1.split()\n",
    "    words2 = str2.split()\n",
    "\n",
    "    # Initialize a counter for differences and a list for the different words\n",
    "    diff_count = 0\n",
    "    diff_words = []\n",
    "\n",
    "    # Get the length of the shorter list to avoid index errors\n",
    "    length = min(len(words1), len(words2))\n",
    "\n",
    "    # Compare words at the same positions\n",
    "    for i in range(length):\n",
    "        if words1[i] != words2[i]:\n",
    "            diff_count += 1\n",
    "            diff_words.append((words1[i], words2[i]))\n",
    "\n",
    "    # Any extra words in one string are also considered as differences\n",
    "    diff_count += abs(len(words1) - len(words2))\n",
    "    diff_words.extend((word, '') for word in words1[length:])\n",
    "    diff_words.extend(('', word) for word in words2[length:])\n",
    "\n",
    "    return diff_count, diff_words\n",
    "\n",
    "# # Test the function\n",
    "# str1 = \"I love to code in Python\"\n",
    "# str2 = \"I love to swim in Python\"\n",
    "\n",
    "# print(compare_strings(str1, str2))  # Output: (1, [('code', 'swim')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2038fd4-c1e1-42b5-b728-1c4744ed0832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(36096, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"/home/dezs/Projects/Nienluan2/ModelStep8\"\n",
    ")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('/home/dezs/Projects/Nienluan2/ModelStep1')\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained('/home/dezs/Projects/Nienluan2/myModelMini')\n",
    "model.to(\"cuda\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d33e2d-e254-4440-a567-a53894dc3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from predict2 import predict\n",
    "\n",
    "# def print_columns(csv_filename):\n",
    "#     # Read the CSV file\n",
    "#     df = pd.read_csv(csv_filename)\n",
    "#     # Loop through each row and print the data in the first and second columns\n",
    "#     for index, row in df.iterrows():\n",
    "#         prediction = predict(model, row['AccentlessSentences'])\n",
    "#         diff_count_1, diff_words_1 = compare_strings(row['AccentlessSentences'], row['Sentences'])\n",
    "#         diff_count_2, diff_words_2 = compare_strings(prediction, row['Sentences'])\n",
    "#         accuracy = (diff_count_1 - diff_count_2) / diff_count_1\n",
    "#         if accuracy < 0:\n",
    "#             accuracy=-1\n",
    "        \n",
    "#         print('Accuracy=', accuracy) \n",
    "#         print(diff_count_1, diff_words_1)\n",
    "#         print(diff_count_2, diff_words_2)\n",
    "\n",
    "# # Call the function with your CSV file\n",
    "# print_columns('myDataset/testDataset.csv')\n",
    "\n",
    "import pandas as pd\n",
    "from predict2 import predict\n",
    "\n",
    "def print_columns(csv_filename):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    \n",
    "    accuracy_list = []\n",
    "    wrong_purpose_count = 0\n",
    "    \n",
    "    # Loop through each row and print the data in the first and second columns\n",
    "    for index, row in df.iterrows():\n",
    "        prediction = predict(model, row['AccentlessSentences'])\n",
    "        diff_count_1, diff_words_1 = compare_strings(row['AccentlessSentences'], row['Sentences'])\n",
    "        diff_count_2, diff_words_2 = compare_strings(prediction, row['Sentences'])\n",
    "        if diff_count_1 != 0:\n",
    "            accuracy = (diff_count_1 - diff_count_2) / diff_count_1\n",
    "            if accuracy < 0:\n",
    "                accuracy=0\n",
    "                wrong_purpose_count=wrong_purpose_count+1\n",
    "        else:\n",
    "            accuracy = 0\n",
    "        print('Accuracy=', accuracy, '; Wrong purpose=', wrong_purpose_count) \n",
    "        print(diff_count_1, diff_words_1)\n",
    "        print(diff_count_2, diff_words_2)\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "    # Calculate the average accuracy\n",
    "    avg_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "\n",
    "    print('Accuracy=', avg_accuracy)\n",
    "\n",
    "# Call the function with your CSV file\n",
    "print_columns('myDataset/testDataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9682daab-f3c2-4015-97ea-5427021cbd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>AccentlessSentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chương trình này là hoạt động đặc biệt của Mob...</td>\n",
       "      <td>Chưong trinh này la hoat dộng dặc biet cua Mob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mang tính thiết thực cao, chương trình được đá...</td>\n",
       "      <td>Mang tinh thiet thuc cao, chương trinh đuoc da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chia sẻ với PV trong buổi lễ công bố, nhiều cô...</td>\n",
       "      <td>Chia se voi PV trong buổi lễ cong bo, nhieu cô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Năm nay thì khác rồi.</td>\n",
       "      <td>Năm nay thi khác roi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cảm kích nhất là cảm giác được đồng cảm và chi...</td>\n",
       "      <td>Cam kích nhat la cảm giác duợc dong cam và chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Để giúp CNVC-LĐ và nhân dân 6 tỉnh Miền Trung ...</td>\n",
       "      <td>Dể giup CNVC-LD va nhan dân 6 tinh Mien Trung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Tại TP Hồ Chí Minh: 43 Hoa Đào, quận Phú Nhuận...</td>\n",
       "      <td>Tai TP Ho Chí Minh: 43 Hoa Đao, quan Phu Nhuan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Báo Lao Động, Quỹ TLV Lao Động chân thành cảm ...</td>\n",
       "      <td>Bao Lao Dộng, Quy TLV Lao Đong chan thành cam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>* LĐLĐ TP.</td>\n",
       "      <td>* LDLĐ TP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Hồ Chí Minh: 500 triệu đồng * Cty CP Bóng đèn ...</td>\n",
       "      <td>Hồ Chi Minh: 500 triệu đồng * Cty CP Bong den ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentences  \\\n",
       "0     Chương trình này là hoạt động đặc biệt của Mob...   \n",
       "1     Mang tính thiết thực cao, chương trình được đá...   \n",
       "2     Chia sẻ với PV trong buổi lễ công bố, nhiều cô...   \n",
       "3                                 Năm nay thì khác rồi.   \n",
       "4     Cảm kích nhất là cảm giác được đồng cảm và chi...   \n",
       "...                                                 ...   \n",
       "4995  Để giúp CNVC-LĐ và nhân dân 6 tỉnh Miền Trung ...   \n",
       "4996  Tại TP Hồ Chí Minh: 43 Hoa Đào, quận Phú Nhuận...   \n",
       "4997  Báo Lao Động, Quỹ TLV Lao Động chân thành cảm ...   \n",
       "4998                                         * LĐLĐ TP.   \n",
       "4999  Hồ Chí Minh: 500 triệu đồng * Cty CP Bóng đèn ...   \n",
       "\n",
       "                                    AccentlessSentences  \n",
       "0     Chưong trinh này la hoat dộng dặc biet cua Mob...  \n",
       "1     Mang tinh thiet thuc cao, chương trinh đuoc da...  \n",
       "2     Chia se voi PV trong buổi lễ cong bo, nhieu cô...  \n",
       "3                                 Năm nay thi khác roi.  \n",
       "4     Cam kích nhat la cảm giác duợc dong cam và chi...  \n",
       "...                                                 ...  \n",
       "4995  Dể giup CNVC-LD va nhan dân 6 tinh Mien Trung ...  \n",
       "4996  Tai TP Ho Chí Minh: 43 Hoa Đao, quan Phu Nhuan...  \n",
       "4997  Bao Lao Dộng, Quy TLV Lao Đong chan thành cam ...  \n",
       "4998                                         * LDLĐ TP.  \n",
       "4999  Hồ Chi Minh: 500 triệu đồng * Cty CP Bong den ...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('myDataset/testDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78e317-17c5-48ec-9de1-0774dcb8ee21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
